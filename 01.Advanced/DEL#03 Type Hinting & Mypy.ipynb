{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69a4be3c-e7f0-4eef-b57d-f387942c8286",
   "metadata": {},
   "source": [
    "# Type Hinting & MyPy í•™ìŠµ\n",
    "- `Typing`ì„ í†µí•œ ì½”ë“œ ë¬¸ë²• ì‹¤ìŠµ\n",
    "- `MyPy`ë¥¼ í†µí•œ ì˜¤ë¥˜ ê²€ìˆ˜\n",
    "- ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ íŒŒì´í”„ë¼ì¸ ì„¤ê³„ í•™ìŠµ\n",
    "\n",
    "| **ë‹¨ê³„**       | **ì£¼ìš” ë‚´ìš©**                           | **ì»¤ë¦¬ í˜ëŸ¼**    |\n",
    "| ------------ | ----------------------------------- | ------------ |\n",
    "| **1. ê¸°ì´ˆ ì„¤ê³„** | Pydantic ëª¨ë¸ë§, Genericì„ ì´ìš©í•œ ì¶”ìƒí™”      | **ì§„í–‰ ì˜ˆì •** ğŸ”„     |\n",
    "| **2. ì•„í‚¤í…ì²˜**  | Protocolì„ ì´ìš©í•œ ì¸í„°í˜ì´ìŠ¤ ì„¤ê³„, ETL êµ¬ì¡°      | **ì§„í–‰ ì˜ˆì •** ğŸ”„     |\n",
    "| **3. ì•ˆì •ì„±**   | Try-Exceptë¥¼ í™œìš©í•œ DLQ ì „ëµ, ì—ëŸ¬ ë¶„ë¥˜       | **ì§„í–‰ ì˜ˆì •** ğŸ”„  |\n",
    "| **4. ìµœì í™”**   | **ë¹„ë™ê¸°(Async) ì²˜ë¦¬, gather, ì„¸ë§ˆí¬ì–´(ì œí•œ)** | **ì§„í–‰ ì˜ˆì •** ğŸ”œ |\n",
    "| **5. ì‹¤ì „ ì‘ìš©** | ì‹¤ì œ API í˜¸ì¶œ ì—°ë™ ë° ëŒ€ìš©ëŸ‰ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜        | **ìµœì¢… ëª©í‘œ** ğŸ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8884b7a2-259c-4121-946f-eb33de2f659c",
   "metadata": {},
   "source": [
    "## 1. ë³€ìˆ˜ì™€ í•¨ìˆ˜ì˜ ê¸°ì´ˆ íƒ€ì… ì§€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f941bc0-6c84-4e7b-82d1-83afb50f9016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³€ìˆ˜ íƒ€ì… ì§€ì •\n",
    "user_id: int = 12345\n",
    "user_name: str = \"Gemini\"\n",
    "\n",
    "# í•¨ìˆ˜ íƒ€ì… ì§€ì •\n",
    "def greet(name: str) -> str:\n",
    "    return f\"Hello, {name}!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900a906c-72d9-45dd-88ab-a961d9bf6b51",
   "metadata": {},
   "source": [
    "## 2. ë³µì¡í•œ êµ¬ì¡°ë¥¼ ìœ„í•œ `typing` ëª¨ë“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f40886a-ad0c-4031-86ba-fd4380a90c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional, Union\n",
    "\n",
    "# ì •ìˆ˜ë“¤ë¡œ ì´ë£¨ì–´ì§„ ë¦¬ìŠ¤íŠ¸\n",
    "scores: List[int] = [90, 85, 100]\n",
    "\n",
    "# í‚¤ëŠ” ë¬¸ìì—´, ê°’ì€ ì •ìˆ˜ì¸ ë”•ì…”ë„ˆë¦¬\n",
    "user_ages: Dict[str, int] = {\"Alice\": 25, \"Bob\": 30}\n",
    "\n",
    "# ë¬¸ìì—´ì´ê±°ë‚˜ Noneì¼ ìˆ˜ ìˆëŠ” ê²½ìš°\n",
    "middle_name: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c89c92b-b853-4bb7-9896-0e12625b48a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "10ì´ì‹­\n"
     ]
    }
   ],
   "source": [
    "# 2ê°œì˜ ì •ìˆ˜ë¥¼ ë°›ì€ í›„ í•©ì‚°í•œ ê°’ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "result = add_numbers(10, 20)\n",
    "print(result)\n",
    "\n",
    "# str íƒ€ì…ì„ ì¸ìˆ˜ë¡œ ë°›ì„ ê²½ìš°ëŠ”?\n",
    "result = add_numbers(\"10\", \"ì´ì‹­\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab8f11a-6052-41b8-8f41-9d17b90e7600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n"
     ]
    }
   ],
   "source": [
    "# ì •ìˆ˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì€ í›„ (í•©ì‚° / ë¦¬ìŠ¤íŠ¸ì˜ ê°œìˆ˜)ë¥¼ ë°˜í™˜ \n",
    "def calculate_average(numbers: list[int]) -> int:\n",
    "    return sum(numbers) / len(numbers)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "nums = [10, 20, 30]\n",
    "print(calculate_average(nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e82b433b-2668-406d-98b6-82284c8e5a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "# 1. ì •ìˆ˜ ì—°ì‚°ë§Œ í—ˆìš©í•˜ë„ë¡ ì •ì˜\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "# 2 & 3. float ë°˜í™˜ ë° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬(Optional)\n",
    "def calculate_average(numbers: List[int]) -> Optional[float]:\n",
    "    if not numbers:  # ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì„ ê²½ìš°\n",
    "        return None\n",
    "    return sum(numbers) / len(numbers)\n",
    "\n",
    "# ì •ìƒ í˜¸ì¶œ\n",
    "print(add_numbers(10, 20))           # ê²°ê³¼: 30\n",
    "print(calculate_average([10, 20, 30]))  # ê²°ê³¼: 15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a98230-d89d-4776-b284-4ffe950e1633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì²˜ë¦¬ ì¤‘: 10\n",
      "ì²˜ë¦¬ ì¤‘: 20.5\n",
      "ì²˜ë¦¬ ì¤‘: 30\n",
      "ì²˜ë¦¬ ì¤‘: 40\n"
     ]
    }
   ],
   "source": [
    "# ì •ìˆ˜(int)ì™€ ì‹¤ìˆ˜(float)ì„ ëª¨ë‘ ë‹´ì„ ìˆ˜ ìˆëŠ” ë¦¬ìŠ¤íŠ¸\n",
    "def process_nbs(data: List[Union[int, float]]) -> None:\n",
    "    for item in data:\n",
    "        print(f\"ì²˜ë¦¬ ì¤‘: {item}\")\n",
    "        \n",
    "# 1. ì •ìˆ˜ì™€ ì‹¤ìˆ˜ê°€ ì„ì¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë„£ì„ ì‹œ / \"40\"ì˜ ë¦¬ìŠ¤íŠ¸ str íƒ€ì… ì¸ìˆ˜ ê°’ì€ MyPyì—ì„œ ì˜¤ë¥˜ë¡œ ê²€ìˆ˜ ë¨.\n",
    "process_nbs([10, 20.5, 30, \"40\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899263e3-a7ba-4492-9f42-7c0d3d94e6e8",
   "metadata": {},
   "source": [
    "## 3. í˜„ì—…ì˜ í‘œì¤€ Pydanticê³¼ MyPy\n",
    "- ë‹¨ìˆœí•œ íƒ€ì… ì²´í¬ë¥¼ ë„˜ì–´ì„œ ë“¤ì–´ì˜¤ëŠ” ë°ì´í„°ì˜ í˜•ì‹ì„ ê°•ì œí•˜ê³  ê²€ì¦(Validation)í•˜ëŠ” ë°©ë²• ì•Œì•„ë³´ê¸°\n",
    "- Pydantic + MyPy\n",
    "    + Pydantic: `\"123\"`ì´ë¼ëŠ” ë¬¸ìì—´ì´ ë“¤ì–´ì™€ë„ int íƒ€ì… ì„ ì–¸ì„ ë³´ê³  `123`ìœ¼ë¡œ ìë™ í˜•ë³€í™˜\n",
    "    + IDE ì§€ì›: MyPy ë•ë¶„ì— ì½”ë“œë¥¼ ì˜ ë•Œ `user1.` ê¹Œì§€ë§Œ íƒ€ì´í•‘í•´ë„ `id`, `name` ê°™ì€ í•„ë“œëª…ì´ ìë™ ì™„ì„±\n",
    "    + ë³µì¡í•œ ì¤‘ì²© êµ¬ì¡°: ë¦¬ìŠ¤íŠ¸ ì•ˆì— ë”•ì…”ë„ˆë¦¬ê°€ ìˆê³ , ê·¸ ì•ˆì— ë˜ ë¦¬ìŠ¤íŠ¸ê°€ ìˆëŠ” ë³µì¡í•œ JSON ë°ì´í„°ë„ ëª…í™•í•˜ê²Œ íƒ€ì…ì„ ì •ì˜í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b647ad9-2fd9-48a7-b9b9-e0e5db8851e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Optional, Union\n",
    "\n",
    "# ë°ì´í„° êµ¬ì¡°(ìŠ¤í‚¤ë§ˆ) ì •ì˜\n",
    "class User(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "    email: Optional[str] = None\n",
    "    friends: List[int] = []\n",
    "\n",
    "# 1. ì •ìƒì ì¸ ë°ì´í„° ìƒì„±\n",
    "user1 = User(id=1, name=\"Alice\", email=\"Alice@example.com\")\n",
    "print(user1.id) # MyPyëŠ” user1.idê°€ intì„ì„ ì•Œê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "# 2. ì˜ëª»ëœ ë°ì´í„°ê°€ ë“¤ì–´ì˜¬ ê²½ìš° (ì‹¤í–‰ ì‹œ ì—ëŸ¬ ë°œìƒ)\n",
    "# user2 = User(id=\"wrong\", name=\"Bob\") # idì— ìˆ«ìê°€ ì•„ë‹Œ ê°’ì´ ì˜¤ë©´ Pydanticì´ ë§‰ì•„ì¤Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5793ff5f-7d69-4a32-baf5-69ea6e15fd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id=101 price=15.5 tags=['eletronics', 'gift']\n"
     ]
    }
   ],
   "source": [
    "class Order(BaseModel):\n",
    "    order_id: int\n",
    "    price: float\n",
    "    tags: List[str] = []\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
    "my_order = Order(order_id = 101, price = 15.5, tags=[\"eletronics\", \"gift\"])\n",
    "print(my_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53171abc-ae54-42a9-a0cb-7e80fda8aa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id=101 price=15.5 tags=['eletronics', 'gift']\n"
     ]
    }
   ],
   "source": [
    "# ìˆ«ìê°€ ì•„ë‹Œ ë¬¸ìì—´ì„ ê¸°ì…í•˜ë©´? >>> ìë™ í˜• ë³€í™˜\n",
    "my_order = Order(order_id = \"101\", price = 15.5, tags=[\"eletronics\", \"gift\"])\n",
    "print(my_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1326c899-2ece-4eac-9735-64a401ecd16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n---------------------------------------------------------------------------\\nValidationError                           Traceback (most recent call last)\\nCell In[10], line 2\\n      1 # í•„ìˆ˜ í•­ëª©ì¸ order_idë¥¼ ëˆ„ë½í•œë‹¤ë©´? >>> `ValidationError` ì—ëŸ¬ ë°œìƒí•˜ì—¬ í”„ë¡œê·¸ë¨ ì¤‘ë‹¨\\n----> 2 my_order = Order(price = 15.5, tags=[\"eletronics\", \"gift\"])\\n      3 print(my_order)\\n\\nFile ~/venv/lib/python3.11/site-packages/pydantic/main.py:250, in BaseModel.__init__(self, **data)\\n    248 # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\\n    249 __tracebackhide__ = True\\n--> 250 validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\\n    251 if self is not validated_self:\\n    252     warnings.warn(\\n    253         \\'A custom validator is returning a value other than `self`.\\n\\'\\n    254         \"Returning anything other than `self` from a top level model validator isn\\'t supported when validating via `__init__`.\\n\"\\n    255         \\'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\\',\\n    256         stacklevel=2,\\n    257     )\\n\\nValidationError: 1 validation error for Order\\norder_id\\n  Field required [type=missing, input_value={\\'price\\': 15.5, \\'tags\\': [\\'eletronics\\', \\'gift\\']}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.12/v/missing\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í•„ìˆ˜ í•­ëª©ì¸ order_idë¥¼ ëˆ„ë½í•œë‹¤ë©´? >>> `ValidationError` ì—ëŸ¬ ë°œìƒí•˜ì—¬ í”„ë¡œê·¸ë¨ ì¤‘ë‹¨\n",
    "# my_order = Order(price = 15.5, tags=[\"eletronics\", \"gift\"])\n",
    "# print(my_order)\n",
    "\"\"\"\n",
    "---------------------------------------------------------------------------\n",
    "ValidationError                           Traceback (most recent call last)\n",
    "Cell In[10], line 2\n",
    "      1 # í•„ìˆ˜ í•­ëª©ì¸ order_idë¥¼ ëˆ„ë½í•œë‹¤ë©´? >>> `ValidationError` ì—ëŸ¬ ë°œìƒí•˜ì—¬ í”„ë¡œê·¸ë¨ ì¤‘ë‹¨\n",
    "----> 2 my_order = Order(price = 15.5, tags=[\"eletronics\", \"gift\"])\n",
    "      3 print(my_order)\n",
    "\n",
    "File ~/venv/lib/python3.11/site-packages/pydantic/main.py:250, in BaseModel.__init__(self, **data)\n",
    "    248 # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n",
    "    249 __tracebackhide__ = True\n",
    "--> 250 validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
    "    251 if self is not validated_self:\n",
    "    252     warnings.warn(\n",
    "    253         'A custom validator is returning a value other than `self`.\\n'\n",
    "    254         \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n",
    "    255         'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n",
    "    256         stacklevel=2,\n",
    "    257     )\n",
    "\n",
    "ValidationError: 1 validation error for Order\n",
    "order_id\n",
    "  Field required [type=missing, input_value={'price': 15.5, 'tags': ['eletronics', 'gift']}, input_type=dict]\n",
    "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bc5dd7-2ef0-441e-bfb3-8754c14fceb3",
   "metadata": {},
   "source": [
    "## 4. MyPy ì„¤ì •\n",
    "- MyPy ì„¤ì •ì´ë€ í”„ë¡œì íŠ¸ ì „ì²´ì˜ 'ê·œì¹™'ì„ ì •í•˜ì—¬ íŒ€ë‚´ í˜‘ì—…ì„ ìƒìŠ¹ì‹œí‚¤ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
    "- `mypy.ini`ë‚˜ `project.toml` íŒŒì¼ì„ ë§Œë“¤ì–´ MyPy ì„¤ì •ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "| **ì„¤ì • í‚¤ ğŸ”‘**                  | **ì—­í•  ğŸ› ï¸**            | **ì¤‘ìš”ì„± ë° íš¨ê³¼ ğŸ’¡**                                                                  |\n",
    "| ---------------------------- | --------------------- | -------------------------------------------------------------------------------- |\n",
    "| **`disallow_untyped_defs`**  | íƒ€ì… íŒíŠ¸ê°€ ì—†ëŠ” í•¨ìˆ˜ ì •ì˜ ê¸ˆì§€    | ëª¨ë“  í•¨ìˆ˜ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ ëª…í™•íˆ ê¸°ë¡í•˜ë„ë¡ ê°•ì œí•˜ì—¬ ì½”ë“œì˜ ê°€ë…ì„±ê³¼ ì•ˆì •ì„±ì„ ë†’ì…ë‹ˆë‹¤.                                |\n",
    "| **`ignore_missing_imports`** | íƒ€ì… ì •ë³´ê°€ ì—†ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬´ì‹œ    | `pandas`ë‚˜ `numpy`ì²˜ëŸ¼ íƒ€ì… íŒíŠ¸ê°€ ë‚´ì¥ë˜ì–´ ìˆì§€ ì•Šì€ ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ë°œìƒí•˜ëŠ” ë¶ˆí•„ìš”í•œ ì—ëŸ¬ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.            |\n",
    "| **`no_implicit_optional`**   | ì•”ì‹œì ì¸ `Optional` ì‚¬ìš© ê¸ˆì§€ | `name: str = None` ëŒ€ì‹  `Optional[str]`ë¥¼ ëª…ì‹œí•˜ê²Œ í•˜ì—¬, ê°’ì´ ë¹„ì–´ ìˆì„ ê°€ëŠ¥ì„±ì„ ê°œë°œìê°€ í™•ì‹¤íˆ ì¸ì§€í•˜ê²Œ í•©ë‹ˆë‹¤. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78138c6a-755d-4d63-867b-510101fba064",
   "metadata": {},
   "source": [
    "## 5. ì‹¤ì „ ë°ì´í„° ì²˜ë¦¬(JSON LIST ì²˜ë¦¬)\n",
    " - ì™¸ë¶€ APIë¥¼ í†µí•˜ì—¬ ì—¬ëŸ¬ ëª…ì˜ ìœ ì € ì •ë³´ê°€ ë‹´ê¸´ JSON ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.\n",
    " - ì´ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ ìœ íš¨í•œ ìœ ì € ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a0b715-0721-43a5-bdba-147da15e3644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ëª»ëœ ë°ì´í„° ìŠ¤í‚µ: {'name': 'Unknown', 'age': 30} | ì´ìœ : 1 validation error for User\n",
      "id\n",
      "  Field required [type=missing, input_value={'name': 'Unknown', 'age': 30}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ìœ ì € ìˆ˜: 2\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, ValidationError\n",
    "from typing import List, Optional\n",
    "\n",
    "# 1. ìœ ì € ëª¨ë¸ ì •ì˜\n",
    "class User(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "    age: Optional[int] = None\n",
    "\n",
    "# 2. ìœ ì € ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "# ì…ë ¥ ê°’ íƒ€ì… = 'raw_data'ë¼ëŠ” ë¦¬ìŠ¤íŠ¸, ê²°ê³¼ëŠ” 'User' ê°ì²´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸\n",
    "def process_user_batch(raw_data: List[dict]) -> List[User]:\n",
    "    valid_users: List[User] = []\n",
    "\n",
    "    for item in raw_data:\n",
    "        try:\n",
    "            # Pydantic ëª¨ë¸ë¡œ ë³€í™˜ (ìë™ ê²€ì¦)\n",
    "            user = User(**item)\n",
    "            valid_users.append(user)\n",
    "        except ValidationError as e:\n",
    "            print(f\"ì˜ëª»ëœ ë°ì´í„° ìŠ¤í‚µ: {item} | ì´ìœ : {e}\")\n",
    "    \n",
    "    return valid_users\n",
    "\n",
    "# 3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "data_from_api = [\n",
    "    {\"id\": 1, \"name\": \"Alice\", \"age\": 25},\n",
    "    {\"id\": \"2\", \"name\": \"Bob\"}, # idì˜ str íƒ€ì…ì€ ìë™ìœ¼ë¡œ int í˜• ë³€í™˜ë¨. ageëŠ” Optional None í—ˆìš©\n",
    "    {\"name\": \"Unknown\", \"age\": 30} # idê°€ ì—†ì–´ì„œ ì‹¤íŒ¨í•  ë°ì´í„°\n",
    "]\n",
    "\n",
    "processed = process_user_batch(data_from_api)\n",
    "print(f\"ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ìœ ì € ìˆ˜: {len(processed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d211928-a148-45d1-bde9-2ffc09197c0c",
   "metadata": {},
   "source": [
    "### ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì¢…í•© ì‹¤ìŠµ\n",
    "ì›¹ì‚¬ì´íŠ¸ ë¡œê·¸ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ ë¶„ì„ìš© ë°ì´í„°ë¡œ ë³€í™˜í•˜ëŠ” ì‘ì—… ìˆ˜í–‰\n",
    "\n",
    "ì¡°ê±´: \n",
    "1. ë¡œê·¸ ëª¨ë¸(`LogRecord`): `timestamp(str)`, `event_type(str)`, `user_id(Optional[int])` í•„ë“œë¥¼ ê°€ì§‘ë‹ˆë‹¤. \n",
    "2. í´ë Œì§• í•¨ìˆ˜: ë¡œê·¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì„œ, `user_id`ê°€ ìˆëŠ” ë°ì´í„°ë§Œ ê³¨ë¼ë‚´ì–´ `LogRecord` ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "784a8a5a-915c-41f1-a29a-cab5e1791064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í´ë Œì§• ëœ ë¡œê·¸: timestamp='2025-12-25 17:40' event_type='click' user_id=123\n",
      "í´ë Œì§• ëœ ë¡œê·¸: timestamp='2025-12-25 17:42' event_type='login' user_id=456\n",
      "í´ë Œì§• ëœ ë¡œê·¸ ìˆ˜: 2\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, ValidationError\n",
    "from typing import List, Optional\n",
    "\n",
    "# 1. ëª¨ë¸ ì •ì˜\n",
    "class LogRecord(BaseModel):\n",
    "    timestamp: str\n",
    "    event_type: str\n",
    "    user_id: Optional[int] = None\n",
    "\n",
    "# 2. íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜\n",
    "def clean_logs(raws_logs: List[dict]) -> List[LogRecord]:\n",
    "    clean_data: List[LogRecord] = []\n",
    "\n",
    "    for log in raw_logs:\n",
    "        try:\n",
    "            record = LogRecord(**log)\n",
    "            # user_idê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "            if record.user_id is not None:\n",
    "                clean_data.append(record)\n",
    "        except ValidationError:\n",
    "            continue\n",
    "    \n",
    "    return clean_data\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
    "raw_logs = [\n",
    "    {\"timestamp\": \"2025-12-25 17:40\", \"event_type\": \"click\", \"user_id\": 123},\n",
    "    {\"timestamp\": \"2025-12-25 17:41\", \"event_type\": \"view\"}, # user_id ê°’ Null\n",
    "    {\"timestamp\": \"2025-12-25 17:42\", \"event_type\": \"login\", \"user_id\": \"456\"} # user_id intë¡œ ìë™ í˜• ë³€í™˜\n",
    "]\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "final_logs = clean_logs(raw_logs)\n",
    "for item in final_logs:\n",
    "    print(f\"í´ë Œì§• ëœ ë¡œê·¸: {(item)}\")\n",
    "print(f\"í´ë Œì§• ëœ ë¡œê·¸ ìˆ˜: {len(final_logs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36836a4-8e15-4d40-94d5-db4387d34c2f",
   "metadata": {},
   "source": [
    "## 6. ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ íƒ€ì… ê´€ë¦¬ ì•„í‚¤í…ì³\n",
    "- ì‹¤ë¬´ì—ì„œëŠ” ë°ì´í„°ê°€ íŒŒì´í”„ë¼ì¸ì„ í†µê³¼í•  ë•Œ ë§ˆë‹¤ íƒ€ì…ì˜ ì„±ê²©ì´ ì¡°ê¸ˆì”© ë³€í•©ë‹ˆë‹¤.\n",
    "- ê·¸ë¦¬ê³  ë‹¤ìŒê³¼ ê°™ì€ íŒ¨í„´ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    + Interface(ì¶”ìƒí™”) í™œìš©: ë°ì´í„° ì†ŒìŠ¤ê°€ S3ì´ë“ , MySQLì´ë“  ê´€ê³„ì—†ì´ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì½ì–´ì˜¬ ìˆ˜ ìˆê²Œ ì„¤ê³„í•©ë‹ˆë‹¤.\n",
    "    + Generic í™œìš©: ì–´ë–¤ ì¢…ë¥˜ì˜ ë°ì´í„° ëª¨ë¸ì´ ë“¤ì–´ì˜¤ë”ë¼ë„ ë™ì¼í•œ í´ë Œì§• ë¡œì§ì„ ì ìš©í•  ìˆ˜ ìˆëŠ” 'ë²”ìš© ì²˜ë¦¬ê¸°'ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "\n",
    "| **ë‹¨ê³„**                     | **íƒ€ì… ê´€ë¦¬ ì „ëµ ğŸ› ï¸**              | **ì—­í•  ë° ë„êµ¬ ğŸ’¡**                                       |\n",
    "| -------------------------- | ----------------------------- | ---------------------------------------------------- |\n",
    "| **1. Extraction (ì¶”ì¶œ)**     | **Raw Type (Any/Dict)**       | ì›ì²œ ë°ì´í„°(JSON, CSV ë“±)ë¥¼ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤. ì´ë•ŒëŠ” íƒ€ì…ì´ ë¶ˆë¶„ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. |\n",
    "| **2. Validation (ê²€ì¦)**     | **Strict Schema (Pydantic)**  | ì™¸ë¶€ ë°ì´í„°ë¥¼ ìš°ë¦¬ê°€ ì •ì˜í•œ ëª¨ë¸(Pydantic)ì— ë„£ì–´ íƒ€ì…ì„ ê°•ì œí•˜ê³  ì •ì œí•©ë‹ˆë‹¤.     |\n",
    "| **3. Transformation (ë³€í™˜)** | **Domain Models (Type Hint)** | ì •ì œëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì´ë•Œ ì œë„¤ë¦­ê³¼ ì¶”ìƒí™”ê°€ ë¹›ì„ ë°œí•©ë‹ˆë‹¤.  |\n",
    "| **4. Loading (ì ì¬)**        | **Database Schema**           | ìµœì¢… íƒ€ì…ì„ DB ìŠ¤í‚¤ë§ˆ(SQL ë“±)ì™€ ì¼ì¹˜ì‹œì¼œ ì €ì¥í•©ë‹ˆë‹¤.                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a77d4f9b-782b-4ca3-b54a-3714ef55253e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í´ë Œì§• ëœ ë¡œê·¸: timestamp='2025-12-25 17:40' event_type='click' user_id=123\n",
      "í´ë Œì§• ëœ ë¡œê·¸: timestamp='2025-12-25 17:42' event_type='login' user_id=456\n",
      "í´ë Œì§• ëœ ë¡œê·¸ ìˆ˜: 2\n"
     ]
    }
   ],
   "source": [
    "# Genericê³¼ ì¶”ìƒí™”(Abstraction): ìœ ì—°í•œ ì½”ë“œ ì§œê¸°\n",
    "# Generic í•™ìŠµ\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import List, TypeVar, Optional\n",
    "\n",
    "# 1. ì œë„¤ë¦­ íƒ€ì… ë³€ìˆ˜ Të¥¼ ì •ì˜. (BaseModelì„ ìƒì†ë°›ì€ í´ë˜ìŠ¤ë§Œ í—ˆìš©)\n",
    "T = TypeVar(\"T\", bound=BaseModel)\n",
    "\n",
    "# 2. ë²”ìš© í•¨ìˆ˜ ì •ì˜\n",
    "def filter_not_none(data_list: List[T], field_name: str) -> List[T]:\n",
    "    result: List[T] = []\n",
    "\n",
    "    for item in data_list:\n",
    "        # getattrë¥¼ ì‚¬ìš©í•˜ë©´ ë¬¸ìì—´ë¡œ ëœ í•„ë“œ ì´ë¦„ìœ¼ë¡œ ê°’ì— ì ‘ê·¼í•  ìˆ˜ ìˆë‹¤.\n",
    "        value = getattr(item, field_name)\n",
    "        if value is not None:\n",
    "            result.append(item)\n",
    "    return result\n",
    "\n",
    "# 3. í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
    "raw_logs = [\n",
    "    {\"timestamp\": \"2025-12-25 17:40\", \"event_type\": \"click\", \"user_id\": 123},\n",
    "    {\"timestamp\": \"2025-12-25 17:41\", \"event_type\": \"view\"}, # user_id ê°’ Null\n",
    "    {\"timestamp\": \"2025-12-25 17:42\", \"event_type\": \"login\", \"user_id\": \"456\"} # user_id intë¡œ ìë™ í˜• ë³€í™˜\n",
    "]\n",
    "\n",
    "# 4. Pydantic ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ê²€ì¦)\n",
    "log_objects = [LogRecord(**log) for log in raw_logs]\n",
    "\n",
    "# 5. ì œë„¤ë¦­ í•¨ìˆ˜ í˜¸ì¶œ\n",
    "final_logs = filter_not_none(data_list = log_objects, field_name = \"user_id\")\n",
    "\n",
    "# 6. ê²°ê³¼ ì¶œë ¥\n",
    "for item in final_logs:\n",
    "    print(f\"í´ë Œì§• ëœ ë¡œê·¸: {item}\")\n",
    "print(f\"í´ë Œì§• ëœ ë¡œê·¸ ìˆ˜: {len(final_logs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1656c5-bb64-4515-a026-af3c9729d5ed",
   "metadata": {},
   "source": [
    "### ì¶”ìƒí™” ì•„í‚¤í…ì³: ì¸í„°í˜ì´ìŠ¤ì™€ êµ¬í˜„ì˜ ë¶„ë¦¬\n",
    "\n",
    "| **êµ¬ì„± ìš”ì†Œ**                  | **ì—­í• **                          | **ë¹„ìœ  ğŸ’¡**                    |\n",
    "| -------------------------- | ------------------------------- | ---------------------------- |\n",
    "| **Protocol (Interface)**   | ë™ì‘ì˜ ê·œì¹™ ì •ì˜ (`fetch_data`ê°€ ìˆì–´ì•¼ í•¨) | ê°€ì „ì œí’ˆì˜ **220V í”ŒëŸ¬ê·¸ ê·œê²©**        |\n",
    "| **Implementation (Class)** | ì‹¤ì œ ë™ì‘ êµ¬í˜„ (S3ì—ì„œ ì½ê¸°, DBì—ì„œ ì½ê¸°)     | ê·œê²©ì— ë§ê²Œ ë§Œë“¤ì–´ì§„ **ëƒ‰ì¥ê³ , TV, ì„¸íƒê¸°** |\n",
    "| **Client (Function)**      | ê·œê²©ì„ ì‚¬ìš©í•˜ëŠ” ë¡œì§ (`run_pipeline`)    | í”ŒëŸ¬ê·¸ë¥¼ ê½‚ì•„ì„œ ì‚¬ìš©í•˜ëŠ” **ë²½ë©´ ì½˜ì„¼íŠ¸**     |\n",
    "\n",
    "ë°ì´í„° ì†ŒìŠ¤ê°€ `Google Drive`ë¡œ ë°”ë€Œë”ë¼ë„ `run_pipeline`ëŠ” ìˆ˜ì •í•  í•„ìš” ì—†ë‹¤.\n",
    "\n",
    "`GoogleDriveReader`ë§Œ ë„£ìœ¼ë©´ ë¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bec58b2-5265-4210-ba07-cc6376f290c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶”ìƒí™”(Abstraction) í•™ìŠµ\n",
    "from typing import Protocol, List\n",
    "\n",
    "class DataReader(Protocol):\n",
    "    def fetch_data(self) -> List[dict]:        \n",
    "        ... # ...(Ellipsis) = êµ¬ì¡°ë§Œ ì •ì˜\n",
    "        ### ë°ì´í„°ë¥¼ ì½ì–´ì„œ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ëŠ” ê·œê²© ###\n",
    "\n",
    "class S3Reader:\n",
    "    def fetch_data(self) -> List[dict]:\n",
    "        print(\"S3ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...\")\n",
    "        return [{\"timestamp\": \"2025-12-25\", \"event_type\": \"Click\", \"user_id\": 1}]\n",
    "\n",
    "class LocalFileReader:\n",
    "    def fetch_data(self) -> List[dict]:\n",
    "        print(\"ë¡œì»¬ íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì½ëŠ” ì¤‘...\")\n",
    "        return [{\"id\": 1, \"name\": \"S3_Alice\", \"age\": 27}]\n",
    "\n",
    "class GoogleReader:\n",
    "    def fetch_data(self) -> List[dict]:\n",
    "        print(\"êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ ë°ì´í„° ì½ëŠ” ì¤‘...\")\n",
    "        return [{\"id\": 1, \"name\": \"Seoul Milk\", \"price\": 3000}, \n",
    "                {\"id\": 2, \"name\": \"Got Milk\", \"price\": 2500},\n",
    "                {\"id\": 3, \"name\": \"Emart Milk\", \"price\": 3500}]\n",
    "\n",
    "def run_pipeline(reader: DataReader):\n",
    "    data = reader.fetch_data()\n",
    "    print(f\"ì´{len(data)}ê°œì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74370415-7c1f-448d-b65f-2c0eb0a46c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, TypeVar, Type, Protocol\n",
    "\n",
    "# ì œë„¤ë¦­ íƒ€ì… ì„¤ì •\n",
    "T = TypeVar(\"T\", bound=BaseModel)\n",
    "\n",
    "# ë²”ìš© íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜\n",
    "def universal_pipeline(reader: DataReader, model_class: Type[T]) -> List[T]:\n",
    "    # 1. readerë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    raw_data = reader.fetch_data()\n",
    "\n",
    "    # 2. ê°€ì ¸ì˜¨ raw_data(dict ë¦¬ìŠ¤íŠ¸)ë¥¼ ëª¨ë¸ ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°”ê¿‰ë‹ˆë‹¤.\n",
    "    return [model_class(**item) for item in raw_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31adeade-f963-43be-a37f-e4aca28814ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...\n",
      "ë¡œì»¬ íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì½ëŠ” ì¤‘...\n"
     ]
    }
   ],
   "source": [
    "# S3ì—ì„œ ë¡œê·¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ LogRecord ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ê³  ì‹¶ì„ ë•Œ\n",
    "s3_reader = S3Reader()\n",
    "logs = universal_pipeline(reader=s3_reader, model_class=LogRecord)\n",
    "\n",
    "# ìœ ì € ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ì‹¶ë‹¤ë©´?\n",
    "user_reader = LocalFileReader() # ë‹¤ë¥¸ Readerë„ ê°€ëŠ¥\n",
    "users = universal_pipeline(reader=user_reader, model_class=User) # User ëª¨ë¸ë§Œ ì „ë‹¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5abc55af-a836-4cfc-95c0-be7b128ba5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ ë°ì´í„° ì½ëŠ” ì¤‘...\n",
      "ìƒí’ˆëª…: Seoul Milk, ê°€ê²©: 3000\n",
      "ìƒí’ˆëª…: Got Milk, ê°€ê²©: 2500\n",
      "ìƒí’ˆëª…: Emart Milk, ê°€ê²©: 3500\n"
     ]
    }
   ],
   "source": [
    "# 1. Product ëª¨ë¸ ì •ì˜ (Pydantic)\n",
    "class Product(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "    price: int\n",
    "\n",
    "# 2. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "product_reader = GoogleReader() # ìƒí’ˆ ë°ì´í„°ê°€ S3ì— ìˆë‹¤ê³  ê°€ì •\n",
    "products = universal_pipeline(reader=product_reader, model_class=Product)\n",
    "\n",
    "# 3. ê²°ê³¼ í™•ì¸\n",
    "for p in products:\n",
    "    print(f\"ìƒí’ˆëª…: {p.name}, ê°€ê²©: {p.price}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0687a8fe-1ec9-45cc-bf83-c51b1ad55da9",
   "metadata": {},
   "source": [
    "## 7. ì €ì¥(Write) ê³¼ì •\n",
    " - `DataWriter` í”„ë¡œí† ì½œ\n",
    "\n",
    "```python\n",
    "# 3ê°€ì§€ ë¶€í’ˆì„ ì¡°ë¦½í•´ì„œ ì‹¤í–‰\n",
    "full_pipeline(\n",
    "    reader=EX_Reader,        # ğŸ“¥ ì¶”ì¶œ(Extract) ë‹´ë‹¹\n",
    "    model_class=EX_Product,  # âœ¨ ë³€í™˜(Transform) & ê²€ì¦ ë‹´ë‹¹\n",
    "    writer=EX_Writer         # ğŸ“¤ ì €ì¥(Load) ë‹´ë‹¹\n",
    ")\n",
    "\n",
    "\n",
    "# ì˜ˆì™¸ ìƒí™©(Error Handing) ì¶”ìƒí™”\n",
    "    ## 1. Skip ì „ëµ: ì—ëŸ¬ê°€ ë‚œ ë°ì´í„°ë§Œ ë²„ë¦¬ê³  ë‚˜ë¨¸ì§€ëŠ” ê³„ì† ì§„í–‰í•œë‹¤.\n",
    "    ## 2. Stop ì „ëµ: í•˜ë‚˜ë¼ë„ ì—ëŸ¬ê°€ ë‚˜ë©´ ì¦‰ì‹œ ì¤‘ë‹¨í•˜ê³  ê´€ë¦¬ìì—ê²Œ ì•Œë¦°ë‹¤.\n",
    "    ## 3. DLQ(Dead Letter Queue) ì „ëµ: ì—ëŸ¬ ë‚œ ë°ì´í„°ë§Œ ë”°ë¡œ ëª¨ì•„ì„œ ë‚˜ì¤‘ì— ë‹¤ì‹œ í™•ì¸í•œë‹¤.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "066c0504-d76a-4d99-88a3-f9913659e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataWriter(Protocol):\n",
    "    def save(self, data: List[BaseModel]) -> None:\n",
    "        ### ë°ì´í„°ë¥¼ íŠ¹ì • ëª©ì ì§€ì— ì €ì¥í•˜ëŠ” ê·œê²© ###\n",
    "        ...\n",
    "\n",
    "# êµ¬í˜„ ì˜ˆì‹œ\n",
    "class ConsoleWriter:\n",
    "    def save(self, data: List[BaseModel]) -> None:\n",
    "        print(f\"--- [ì €ì¥ ì™„ë£Œ] ì´{len(data)}ê°œì˜ ì•„ì´í…œì„ ì €ì¥í•¨ ---\")\n",
    "\n",
    "# ìµœì¢… íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ (ì €ì¥ ë‹¨ê³„)\n",
    "def full_pipeline(reader: DataReader, model_class: Type[T], writer: DataWriter) -> List[T]:\n",
    "    # 1. ì¶”ì¶œ & ë³€í™˜\n",
    "    items = universal_pipeline(reader, model_class)\n",
    "\n",
    "    # 2. ì €ì¥\n",
    "    writer.save(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5106e602-2dba-4662-888f-69731e7acaf3",
   "metadata": {},
   "source": [
    "## 8. DLQ(Dead Letter Queue) ì „ëµ\n",
    "- `try-except` êµ¬ë¬¸ì„ í™œìš©í•˜ì—¬ ì—ëŸ¬ ìƒí™© í•¸ë“¤ë§\n",
    "- `universal_pipeline` êµ¬ì¡°ë¥¼ í™•ì¥í•´ì„œ, ì„±ê³µí•œ ë°ì´í„°ì™€ ì‹¤íŒ¨í•œ ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ëŠ” ë°˜í™˜ êµ¬ì¡° ë§Œë“¤ê¸°\n",
    "\n",
    "| **ë°œìƒ ë‹¨ê³„**          | **ì£¼ìš” ì—ëŸ¬ íƒ€ì…**                            | **ì›ì¸ ì˜ˆì‹œ**                       |\n",
    "| ------------------ | --------------------------------------- | ------------------------------- |\n",
    "| **ì¶”ì¶œ (Extract)**   | `ConnectionError` / `FileNotFoundError` | ë„¤íŠ¸ì›Œí¬ ëŠê¹€, S3 ê¶Œí•œ ë¬¸ì œ, íŒŒì¼ ê²½ë¡œ ì˜¤ë¥˜     |\n",
    "| **ë³€í™˜ (Transform)** | **`ValidationError`**                   | ë°ì´í„° íƒ€ì… ë¶ˆì¼ì¹˜, í•„ìˆ˜ í•„ë“œ ëˆ„ë½ (Pydantic) |\n",
    "| **ì €ì¥ (Load)**      | `OperationalError` / `TimeoutError`     | DB ì„œë²„ ë‹¤ìš´, ì €ì¥ ê³µê°„ ë¶€ì¡±, ì“°ê¸° ì‹œê°„ ì´ˆê³¼    |\n",
    "| **ê¸°íƒ€**             | `KeyError` / `TypeError`                | ë”•ì…”ë„ˆë¦¬ì— ì—†ëŠ” í‚¤ ì ‘ê·¼, ì˜ëª»ëœ ì—°ì‚° ë“±         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9009ea21-98b0-486a-a695-5aed3a1fa348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "from pydantic import ValidationError\n",
    "\n",
    "# TëŠ” ì´ì „ì— ì •ì˜í•œ TypeVar(\"T\", bound=BaseModel)ì…ë‹ˆë‹¤.\n",
    "\n",
    "def pipeline_with_dlq(\n",
    "    reader: DataReader,\n",
    "    model_class: Type[T]\n",
    ") -> Tuple[List[T], List[dict]]: # (ì„±ê³µ ë¦¬ìŠ¤íŠ¸, ì‹¤íŒ¨ ë¦¬ìŠ¤íŠ¸) ë°˜í™˜\n",
    "\n",
    "    success_data: List[T] = []\n",
    "    error_data: List[ditc] = []\n",
    "    raw_data = reader.fetch_data()\n",
    "\n",
    "    for item in raw_data:\n",
    "        try:\n",
    "            # 1. ê²€ì¦ ë° ë³€í™˜ ì‹œë„\n",
    "            instance = model_class(**item)\n",
    "            success_data.append(instance)\n",
    "        except ValidationError as e:\n",
    "            # 2. ì—ëŸ¬ ë°œìƒ ì‹œ 'ì‹¤íŒ¨ ë¦¬ìŠ¤íŠ¸'ì— ì €ì¥\n",
    "            print(f\"ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨! ì´ìœ : {e}\")\n",
    "            error_data.append(item)\n",
    "            \n",
    "    return succes_Data, error_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4a626f-e5bc-472c-a0ac-d424abc56c8c",
   "metadata": {},
   "source": [
    "## 9. Pydantic Fieldë¡œ ê°’ì˜ ë²”ìœ„ ì œí•œí•˜ê¸°\n",
    "- `Field`ë¥¼ ì‚¬ìš©í•˜ë©´ ë‹¨ìˆœí•œ íƒ€ì… ì²´í¬ë¥¼ ë„˜ì–´, ê°’ì˜ í¬ê¸°ë‚˜ ë¬¸ìì—´ì˜ ê¸¸ì´ ë“±ì„ ê²€ì¦í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52ba3e63-1771-4caf-86d3-76a8f74d5627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Product(BaseModel):\n",
    "    id: int\n",
    "    name: str = Field(min_length=2) # min_length=2(ìµœì†Œ 2ê¸€ì ì´ìƒ)\n",
    "    price: int = Field(gt=0) # gt=0: Greater Than 0 (0ë³´ë‹¤ ì»¤ì•¼ í•¨)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1cb5de-5fa2-4e6a-a89d-4c2cb5a081d0",
   "metadata": {},
   "source": [
    "## 10. ë¹„ë™ê¸°(Async) íŒŒì´í”„ë¼ì¸\n",
    "- ì„±ëŠ¥ì„ ê·¹ì ìœ¼ë¡œ ë†’ì´ëŠ” ë¹„ë™ê¸°(Async) ê°œë…\n",
    "- ì‹¤ë¬´ì—ì„œëŠ” APIë¥¼ í˜¸ì¶œí•˜ê±°ë‚˜ DBì— ì €ì¥í•  ë•Œ ê¸°ë‹¤ë¦¬ëŠ” ì‹œê°„(`I/O Wait`)ì´ ë§ì´ ë°œìƒí•©ë‹ˆë‹¤.\n",
    "- ì´ë•Œ **ë¹„ë™ê¸°**ë¥¼ ì‚¬ìš©í•˜ë©´ í•œ ì‘ì—…ì´ ëë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ë‹¤ë¥¸ ì‘ì—…ì„ ë¯¸ë¦¬ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d3c7633-5965-44fc-a02c-00f41649a247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ìš”ì²­ ì‹œì‘!\n",
      "[1] ìš”ì²­ ì‹œì‘!\n",
      "[2] ìš”ì²­ ì‹œì‘!\n",
      "[3] ìš”ì²­ ì‹œì‘!\n",
      "[4] ìš”ì²­ ì‹œì‘!\n",
      "[5] ìš”ì²­ ì‹œì‘!\n",
      "[6] ìš”ì²­ ì‹œì‘!\n",
      "[7] ìš”ì²­ ì‹œì‘!\n",
      "[8] ìš”ì²­ ì‹œì‘!\n",
      "[9] ìš”ì²­ ì‹œì‘!\n",
      "['[0] ì‘ë‹µ ì™„ë£Œ', '[1] ì‘ë‹µ ì™„ë£Œ', '[2] ì‘ë‹µ ì™„ë£Œ', '[3] ì‘ë‹µ ì™„ë£Œ', '[4] ì‘ë‹µ ì™„ë£Œ', '[5] ì‘ë‹µ ì™„ë£Œ', '[6] ì‘ë‹µ ì™„ë£Œ', '[7] ì‘ë‹µ ì™„ë£Œ', '[8] ì‘ë‹µ ì™„ë£Œ', '[9] ì‘ë‹µ ì™„ë£Œ']\n"
     ]
    }
   ],
   "source": [
    "import asyncio #íŒŒì´ì¬ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ì„¤ì¹˜í•  í•„ìš” ì—†ìŒ.\n",
    "\n",
    "async def mock_api_call(i):\n",
    "    print(f\"[{i}] ìš”ì²­ ì‹œì‘!\")\n",
    "    await asyncio.sleep(1) # 1ì´ˆ ë™ì•ˆ ì‘ë‹µì„ ê¸°ë‹¤ë¦°ë‹¤ê³  ê°€ì • (ë¹„ë™ê¸° ëŒ€ê¸°)\n",
    "    return f\"[{i}] ì‘ë‹µ ì™„ë£Œ\"\n",
    "\n",
    "# ì£¼í”¼í„° í™˜ê²½ì—ì„œëŠ” 'await'ë¥¼ ì…€ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "# 10ê°œì˜ ìš”ì²­ì„ ë™ì‹œì— ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "results = await asyncio.gather(*(mock_api_call(i) for i in range(10)))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7eccfd98-a79f-4ef3-b47b-f338c9547d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—ëŸ¬ í•¸ë“¤ë§: try-except ìœ„ì¹˜\n",
    "# DLQ(Dead Letter Queue) ì „ëµì„ ë¹„ë™ê¸° í™˜ê²½ì— ì ìš©í•  ë•Œ ì•„ë˜ì˜ ë‘ ê°€ì§€ ì„ íƒì§€ê°€ ìˆë‹¤.\n",
    "    ## ì¼ê´„ ì²˜ë¦¬ í›„ ê²€ì¦: ëª¨ë“  ë°ì´í„°ë¥¼ ë‹¤ ê°€ì ¸ì˜¨(await) ë‹¤ìŒì— í•œêº¼ë²ˆì— ë£¨í”„ë¥¼ ëŒë©° ê²€ì¦í•œë‹¤.\n",
    "    ## ê°€ì ¸ì˜¤ë©´ì„œ ì¦‰ì‹œ ê²€ì¦: ê°œë³„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¦‰ì‹œ ë¹„ë™ê¸° ë£¨í‹´ ì•ˆì—ì„œ ê²€ì¦í•˜ê³  ì„±ê³µ/ì‹¤íŒ¨ë¥¼ ë‚˜ëˆˆë‹¤.(ì‹¤ë¬´ ì„ í˜¸ ë°©ì‹/ê° ìš”ì²­ ë…ë¦½ì  ì‹¤íŒ¨ ê°€ëŠ¥ì„± ì¡´ì¬)\n",
    "from typing import Protocol, List\n",
    "class AsyncDataReader(Protocol):\n",
    "    # ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê³¼ì •ì´ ë¹„ë™ê¸°(async)ì„ì„ ëª…ì‹œí•©ë‹ˆë‹¤.\n",
    "    async def fetch_data(self) -> List[dict]:\n",
    "        ...\n",
    "\n",
    "async def async_universal_pipeline(\n",
    "    reader: AsyncDataReader, model_class: Type[T]) -> List[T]:\n",
    "\n",
    "    # ë¹„ë™ê¸°ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ë•Œê¹Œì§€ 'ê¸°ë‹¤ë ¤(await)' ì¤ë‹ˆë‹¤.\n",
    "    raw_data = await reader.fetch_data()\n",
    "\n",
    "    return [model_class(**item) for item in raw_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6aa5cc73-d3c4-436a-ab03-172b6f2712b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_item(raw_dict: dict, model_class: Type[T]):\n",
    "    try:\n",
    "        # Pydantic ëª¨ë¸ë¡œ ë³€í™˜ ì‹œë„\n",
    "        return model_class(**raw_dict)\n",
    "    except ValidationERROR:\n",
    "        # ê²€ì¦ ì‹¤íŒ¨ ì‹œ DLQë¡œ ë³´ë‚¼ ë°ì´í„° ë°˜í™˜(Noneì´ë‚˜ íŠ¹ìˆ˜ ê°ì²´)\n",
    "        return \"ERROR_DATA\"\n",
    "\n",
    "async def async_pipeline_with_dlq(reader, model_class):\n",
    "    raw_data = await reader.fetch_data() # [{...}, {...}, ...]\n",
    "\n",
    "    # ëª¨ë“  ë°ì´í„°ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ë™ì‹œì— 'ê²€ì¦' ë£¨í‹´ì— íƒœì›ë‹ˆë‹¤.\n",
    "    tasks = [process_item(item, model_class) for item in raw_data]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    # ê²°ê³¼ ë¶„ë¥˜\n",
    "    success = [r for r in results if r != \"ERROR_DATA\"]\n",
    "    errors = [item for r, item in zip(results, raw_data) if r == \"ERROR_DATA\"]\n",
    "\n",
    "    return success, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "796a6f0f-b341-4109-bd4e-ce731d1ffe49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...\n",
      "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨: object list can't be used in 'await' expression\n"
     ]
    }
   ],
   "source": [
    "async def async_run_pipeline():\n",
    "    try:\n",
    "        # 1. ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ ë°œìƒ ì‹œ ì „ì²´ê°€ ë©ˆì¶°ì•¼ í•©ë‹ˆë‹¤.\n",
    "        success, errors = await async_pipeline_with_dlq(s3_reader, Product)\n",
    "        print(f\"ì„±ê³µ: {len(success)}ê±´, ì‹¤íŒ¨(DLQ): {len(errors)}ê±´\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # 2. ì‹œìŠ¤í…œ ì—ëŸ¬(ë„¤íŠ¸ì›Œí¬, ê¶Œí•œ ë“±)ëŠ” ì—¬ê¸°ì„œ í†µí•© ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "        print(f\"ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨: {e}\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "await async_run_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfec498-3086-4d2d-80d8-ce924292679d",
   "metadata": {},
   "source": [
    "| **ì—ëŸ¬ ìƒí™©**                      | **ë°œìƒ ìœ„ì¹˜**             | **ê²°ê³¼**                                           |\n",
    "| ------------------------------ | --------------------- | ------------------------------------------------ |\n",
    "| **ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜** (ì˜ˆ: `price`ê°€ ìŒìˆ˜) | `process_item` (ë‚´ë¶€)   | í•´ë‹¹ ë°ì´í„°ë§Œ **DLQ**ë¡œ ê°€ê³ , íŒŒì´í”„ë¼ì¸ì€ **ê³„ì† ì‹¤í–‰**ë¨ ğŸƒâ€â™‚ï¸     |\n",
    "| **ë„¤íŠ¸ì›Œí¬/ì„œë²„ ì˜¤ë¥˜** (ì˜ˆ: S3 ì—°ê²° ëŠê¹€)   | `reader.fetch_data()` | `async_run_pipeline`ì˜ `except`ì— ê±¸ë ¤ **ì „ì²´ ì¤‘ë‹¨**ë¨ ğŸ›‘ |\n",
    "\n",
    "### ë¹„ë™ê¸° ì‹¬í™” ê°œë…\n",
    "- asyncio.gather(ë³‘ë ¬ ì‹¤í–‰):\n",
    "    + ì—¬ëŸ¬ ê°œì˜ ì‘ì—…ì„ í•œêº¼ë²ˆì— ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ëª¨ìœ¼ëŠ” ë°©ë²•\n",
    "    + ë°ì´í„°ê°€ 100ê°œë¼ë©´ 100ê°œì˜ ìš”ì²­ì„ ë™ì‹œì— í•  ìˆ˜ ìˆë‹¤.\n",
    "- asyncio.Semaphore(ë™ì‹œì„± ì œí•œ):\n",
    "    + ë™ì‹œì— ìš”ì²­í•  ì‹œ ì„œë²„ê°€ ê³¼ë¶€í™”ë  ìˆ˜ ìˆê¸°ì— ìµœëŒ€ ìš”ì²­ ê°œìˆ˜ë¥¼ ì œí•œí•˜ëŠ” ë°©ë²•\n",
    "    + ë°ì´í„° 100ê°œ ì¤‘ ìµœëŒ€ 5ê°œì”© ìš”ì²­í•˜ë„ë¡ ì œí•œ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebfa79ec-91dc-48a2-8f5d-af9398138914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¸ë§ˆí¬ì–´ ì˜ˆì‹œ\n",
    "import asyncio\n",
    "\n",
    "# í•œ ë²ˆì— 5ê°œê¹Œì§€ë§Œ í—ˆìš©í•˜ëŠ” ì„¸ë§ˆí¬ì–´ ìƒì„±\n",
    "sem = asyncio.Semaphore(5)\n",
    "\n",
    "async def limited_process_item(item, model_class):\n",
    "    # ì„¸ë§ˆí¬ì–´ ì•ˆì—ì„œë§Œ ì‘ì—…ì´ ì‹¤í–‰ë˜ë„ë¡ ì œí•œí•©ë‹ˆë‹¤.\n",
    "    async with sem:\n",
    "        # ì´ ì•ˆì—ì„œëŠ” ìµœëŒ€ 5ê°œì˜ ìš”ì²­ì´ ë°œìƒ ì¤‘ì…ë‹ˆë‹¤.\n",
    "        return await process_item(item, model_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e95c1660-d92a-4fc1-bdb9-c72405528dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì™„ì„±í˜• ë¹„ë™ê¸° íŒŒì´í”„ë¼ì¸ êµ¬ì¡° ì˜ˆì‹œ\n",
    "import asyncio\n",
    "from typing import List\n",
    "\n",
    "class AsyncAPIReader:\n",
    "    async def fetch_data(self) -> List[dict]:\n",
    "        # ì‹¤ì œëŠ” API í˜¸ì¶œì„ í•˜ì§€ë§Œ ì˜ˆì‹œì´ë¯€ë¡œ ë¹„ë™ê¸° ì‹œë®¬ë ˆì´ì…˜ì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "        printf(\"API ì„œë²„ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...\")\n",
    "        await asyncio.sleep(1) # ë„¤íŠ¸ì›Œí¬ ëŒ€ê¸° ì‹œê°„ 1ì´ˆ\n",
    "        return [\n",
    "            {\"id\": 1, \"name\": \"í‚¤ë³´ë“œ\", \"price\": 35000},\n",
    "            {\"id\": 2, \"name\": \"ë§ˆìš°ìŠ¤\", \"price\": -500}, # Error Data !\n",
    "            {\"id\": 3, \"name\": \"ëª¨ë‹ˆí„°\", \"price\": 250000}\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01b72b4c-d056-4204-9925-1ca4f8593314",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = asyncio.Semaphore(3)\n",
    "\n",
    "async def process_item_with_sem(raw_dict: dict, model_class: Type[T]):\n",
    "\n",
    "    # ì„¸ë§ˆí¬ì–´ë¥¼ í†µí•´ 'ë™ì‹œ ì‹¤í–‰' ê°œìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤.\n",
    "    async with sem:\n",
    "        try:\n",
    "            # ì‹¤ì œ í™˜ê²½ì´ë¼ë©´ ì—¬ê¸°ì„œ 'await'ê°€ í•„ìš”í•œ ì¶”ê°€ ì‘ì—…(ì˜ˆì‹œ: DB ì €ì¥)ì´ ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "            instance = model_class(**raw_dict)\n",
    "            return instance\n",
    "        except ValidationError:\n",
    "            return \"ERROR_DATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b3cb7d5-923d-4967-89ca-fad7e3e1353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹„ë™ê¸° íŒŒì´í”„ë¼ì¸ êµ¬í˜„ ì˜ˆì‹œ\n",
    "import asyncio\n",
    "from typing import List, Type, TypeVar, Tuple\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "T = TypeVar(\"T\", bound=BaseModel)\n",
    "\n",
    "class AsyncPipeline:\n",
    "    def __init__(self, model_class: Type[T], concurrency_limit: int = 5):\n",
    "        self.model_class = model_class\n",
    "        # ë™ì‹œì„± ì¡°ì ˆ\n",
    "        self.sem = asyncio.Semaphore(concurrency_limit)\n",
    "\n",
    "    async def _process_item(self, raw_data: dict) -> Tuple[bool, T | dict]:\n",
    "        \"\"\" ê°œë³„ ë°ì´í„° ê²€ì¦ ë° ë³€í™˜ (B ë‹¨ê³„: DLQ) \"\"\"\n",
    "        async with self.sem:\n",
    "            try:\n",
    "                # Pydantic ëª¨ë¸ë¡œ ë³€í™˜ (íƒ€ì… ê°•ì•• ë° í•„ë“œ ê²€ì¦)\n",
    "                instance = self.model_class(**raw_data)\n",
    "                return True, instance\n",
    "            except ValidationError:\n",
    "                return False, raw_data\n",
    "\n",
    "        async def run(self, reader) -> Tuple[List[T], List[dict]]:\n",
    "            \"\"\" ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (A ë‹¨ê³„: ì „ì²´ íë¦„ ì œì–´) \"\"\"\n",
    "            try:\n",
    "                # 1. ë°ì´í„° ì¶”ì¶œ(Extract)\n",
    "                raw_items = await reader.fetch_data()\n",
    "\n",
    "                # 2. ë¹„ë™ê¸° ë³€í™˜(Transform)\n",
    "                tasks = [self._process_item(item) for item in raw_items]\n",
    "                results = await asyncio.gather(*tasks)\n",
    "\n",
    "                # 3. ê²°ê³¼ ë¶„ë¥˜ (ì„±ê³µ vs DLQ)\n",
    "                success = [res for ok, res in results if ok]\n",
    "                errors = [res for ok, res in results if not ok]\n",
    "\n",
    "                return success, errors\n",
    "\n",
    "            except Exception as e:\n",
    "                # ì‹œìŠ¤í…œ ë ˆë²¨ ì—ëŸ¬ ì²˜ë¦¬ (ë„¤íŠ¸ì›Œí¬ ë‹¨ì ˆ ë“±)\n",
    "                print(f\"íŒŒì´í”„ë¼ì¸ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}\")\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9be4decd-f261-43ea-8479-195bf210f44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„±ê³µ ë°ì´í„° (2ê±´): [Product(id=1, name='í‚¤ë³´ë“œ', price=35000), Product(id=4, name='ëª¨ë‹ˆí„°', price=250000)]\n",
      "âŒ DLQ ë°ì´í„° (2ê±´): [{'id': 2, 'name': 'M', 'price': 500}, {'id': 3, 'name': 'ë§ˆìš°ìŠ¤', 'price': -500}]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import List, Type, TypeVar, Tuple\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "T = TypeVar(\"T\", bound=BaseModel)\n",
    "\n",
    "# 1. ë°ì´í„° ëª¨ë¸ ì •ì˜ (ê²€ì¦ ê·œì¹™)\n",
    "class Product(BaseModel):\n",
    "    id: int\n",
    "    name: str = Field(min_length=2)\n",
    "    price: int = Field(gt=0)\n",
    "\n",
    "# 2. ë¹„ë™ê¸° ë¦¬ë” ì‹œë®¬ë ˆì´ì…˜\n",
    "class AsyncAPIReader:\n",
    "    async def fetch_data(self) -> List[dict]:\n",
    "        await asyncio.sleep(1) # ë„¤íŠ¸ì›Œí¬ ëŒ€ê¸° ì‹œë®¬ë ˆì´ì…˜\n",
    "        return [\n",
    "            {\"id\": 1, \"name\": \"í‚¤ë³´ë“œ\", \"price\": 35000},\n",
    "            {\"id\": 2, \"name\": \"M\", \"price\": 500},      # name ë„ˆë¬´ ì§§ìŒ (ì—ëŸ¬)\n",
    "            {\"id\": 3, \"name\": \"ë§ˆìš°ìŠ¤\", \"price\": -500},  # price ìŒìˆ˜ (ì—ëŸ¬)\n",
    "            {\"id\": 4, \"name\": \"ëª¨ë‹ˆí„°\", \"price\": 250000}\n",
    "        ]\n",
    "\n",
    "# 3. ë¹„ë™ê¸° íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤\n",
    "class AsyncPipeline:\n",
    "    def __init__(self, model_class: Type[T], concurrency_limit: int = 2):\n",
    "        self.model_class = model_class\n",
    "        self.sem = asyncio.Semaphore(concurrency_limit)\n",
    "\n",
    "    async def _process_item(self, raw_data: dict) -> Tuple[bool, T | dict]:\n",
    "        async with self.sem:\n",
    "            try:\n",
    "                instance = self.model_class(**raw_data)\n",
    "                return True, instance\n",
    "            except ValidationError:\n",
    "                return False, raw_data\n",
    "\n",
    "    async def run(self, reader) -> Tuple[List[T], List[dict]]:\n",
    "        raw_items = await reader.fetch_data()\n",
    "        tasks = [self._process_item(item) for item in raw_items]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        success = [res for ok, res in results if ok]\n",
    "        errors = [res for ok, res in results if not ok]\n",
    "        return success, errors\n",
    "\n",
    "# 4. ì‹¤í–‰ë¶€\n",
    "async def main():\n",
    "    pipeline = AsyncPipeline(Product)\n",
    "    reader = AsyncAPIReader()\n",
    "    \n",
    "    success, dlq = await pipeline.run(reader)\n",
    "    \n",
    "    print(f\"âœ… ì„±ê³µ ë°ì´í„° ({len(success)}ê±´):\", success)\n",
    "    print(f\"âŒ DLQ ë°ì´í„° ({len(dlq)}ê±´):\", dlq)\n",
    "\n",
    "# ì£¼í”¼í„° ë…¸íŠ¸ë¶ì—ì„œëŠ” ì•„ë˜ì™€ ê°™ì´ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5283edf-da62-4d89-ae9f-e2920518642c",
   "metadata": {},
   "source": [
    "## 11. ë°ì´í„° í†µê³„ í¬í„¸ api ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ ì„¤ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f338ae7-512c-4ab4-ae50-6a76dc27b8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¡œë“œëœ í‚¤ í™•ì¸: 5ndtX...\n"
     ]
    }
   ],
   "source": [
    "# api í‚¤ë¥¼ ìˆ¨ê¸°ê¸° ìœ„í•´ .env íŒŒì¼ì„ ë§Œë“¤ì–´ ë³„ë„ë¡œ ê´€ë¦¬\n",
    "# python-dotenv ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•´ í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"Solar_API_KEY\")\n",
    "\n",
    "print(f\"ë¡œë“œëœ í‚¤ í™•ì¸: {api_key[:5]}...\") # ë³´ì•ˆì„ ìœ„í•´ ì• 5ìë¦¬ê¹Œì§€ë§Œ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0613fcf2-a530-4ec1-a290-65e463203bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding Key: ì›ë³¸ ì—´ì‡ (ë¹„ì••ì¶•)\n",
    "# Encoding Key: í¬ì¥ ì—´ì‡ (ì••ì¶•)\n",
    "# Request ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì••ì¶•ì„ í•´ì„œ ë°ì´í„°ë¥¼ ë°›ìœ¼ë¯€ë¡œ ë¹„ì••ì¶• ìƒíƒœë¡œ ë°›ëŠ”ê²Œ ì¢‹ë‹¤.\n",
    "\n",
    "# API í˜¸ì¶œì— í•„ìš”í•œ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬\n",
    "params = {\n",
    "    \"serviceKey\": api_key, #\n",
    "    \"page\": 1,\n",
    "    \"size\": 1,\n",
    "    \"startD\": \"20250101\",\n",
    "    \"endD\": \"20250102\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d66f2aad-0ca0-4d9b-9555-496b36a70939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reponse': {'header': {'resultCode': '00', 'resultMsg': 'NORMAL SERVICE.'}, 'body': {'content': [{'dgenYmd': '2025-01-01', 'ippt': '84S1', 'hogi': '1', 'ipptNam': 'ì˜ë™íƒœì–‘ê´‘', 'qhorGen01': 0, 'qhorGen02': 0, 'qhorGen03': 0, 'qhorGen04': 0, 'qhorGen05': 0, 'qhorGen06': 0, 'qhorGen07': 0, 'qhorGen08': 0, 'qhorGen09': 0, 'qhorGen10': 17.856, 'qhorGen11': 20.544, 'qhorGen12': 20.16, 'qhorGen13': 20.448, 'qhorGen14': 21.696, 'qhorGen15': 396.768, 'qhorGen16': 490.08, 'qhorGen17': 328.128, 'qhorGen18': 549.6, 'qhorGen19': 689.28, 'qhorGen20': 688.32, 'qhorGen21': 285.408, 'qhorGen22': 0, 'qhorGen23': 0, 'qhorGen24': 0, 'qsum': 3528.288, 'qavg': 147, 'qvodMaxS': 689.28, 'qvodMinS': 17.856, 'qvodMax': 689.28, 'qvodMin': 0, 'eaidml': None, 'eaiflag': None, 'eaimsg': None}], 'totalPages': 46, 'last': False, 'totalElements': 46, 'numberOfElements': 1, 'first': True, 'sort': None, 'size': 1, 'number': 0}}}\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "\n",
    "async def fetch_solar_data():\n",
    "    url = \"https://apis.data.go.kr/B551893/solar-power-by-hour/list\"\n",
    "    \n",
    "    # ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ë¥¼ ì—½ë‹ˆë‹¤.\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        # APIì— ë°ì´í„°ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.\n",
    "        response = await client.get(url, params=params)\n",
    "        \n",
    "        # ê²°ê³¼ê°€ JSON í˜•ì‹ì¸ì§€ í™•ì¸í•˜ê³  ì¶œë ¥í•´ë´…ë‹ˆë‹¤.\n",
    "        # print(\"--- ì„œë²„ì—ì„œ ì˜¨ ì‘ë‹µ ì›ë¬¸ ---\")\n",
    "        # print(response.text)\n",
    "        # print(\"---------------------------\")\n",
    "        return response.json()\n",
    "\n",
    "# ì‹¤í–‰\n",
    "result = await fetch_solar_data()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ece033e-3c20-4ab2-9060-7b0006ea8555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV ì €ì¥ ì™„ë£Œ: solar_power_data_std.csv\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ì €ì¥í•˜ê¸°\n",
    "\n",
    "import csv\n",
    "\n",
    "# 1. ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "items = result['reponse']['body']['content']\n",
    "\n",
    "# 2. CSV í˜•íƒœ ì‘ì„±\n",
    "if items:\n",
    "    # CSV í—¤ë”(ì»¬ëŸ¼ëª…) ê°€ì ¸ì˜¤ê¸°\n",
    "    headers = items[0].keys()\n",
    "\n",
    "    # íŒŒì¼ì„ ì“°ê¸° ëª¨ë“œë¡œ ì—´ê¸° (newline='' = ìœˆë„ìš° ì¤„ ë°”ê¿ˆ ë¬¸ì œ ë°©ì§€)\n",
    "    with open('solar_power_data_std.csv', 'w', newline='', encoding='utf-8-sig') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=headers)\n",
    "\n",
    "        # í—¤ë” ì“°ê¸°\n",
    "        writer.writeheader()\n",
    "\n",
    "        # ë°ì´í„° í–‰ ì“¸ê¸°\n",
    "        writer.writerows(items)\n",
    "\n",
    "    print(\"CSV ì €ì¥ ì™„ë£Œ: solar_power_data_std.csv\")\n",
    "else:\n",
    "    print(\"ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6942e2ef-7b8b-4593-a863-e3b64c5eeb61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
