{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "178afdec-6242-4a28-9039-a637db4a9293",
   "metadata": {},
   "source": [
    "# Json 학습\n",
    "\n",
    "**시스템에 들어와서 → 규격화되고 → 대규모로 확장되는** 논리적 순서에 따른 학습\n",
    "\n",
    "| **단계**  | **주제**                    | **학습 목표**                                                     |\n",
    "| ------- | ------------------------- | ------------------------------------------------------------- |\n",
    "| **1단계** | **평탄화 (Flattening)**    | 복잡하게 얽힌 JSON에서 필요한 데이터를 추출하고 표 형식으로 만드는 법을 익힙니다.              |\n",
    "| **2단계** | **규격화 (Normalization)**  | Pydantic을 사용해 데이터의 타입을 검증하고, 서로 다른 명명 규칙(camelCase 등)을 통일합니다. |\n",
    "| **3단계** | **효율화 (Efficiency)**     | 대용량 데이터를 처리할 때 메모리 부하를 줄이는 파싱 기법을 배웁니다.                       |\n",
    "\n",
    "**단계별 의미**\n",
    "1. 데이터 정형화 단계(데이터 형태)\n",
    "2. 데이터 규격화 단계(데이터 자료형)\n",
    "3. 데이터 효율화 단계(데이터 효율 처리)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68902245-9c15-49f2-bbaf-42e574d3dd22",
   "metadata": {},
   "source": [
    "## 1단계: 평탄화(Flattening)\n",
    "\n",
    "평탄화(Flattening)란?\n",
    "데이터 분석 도구(Pandas 등)나 데이터베이스는 보통 표(Table) 형태를 선호합니다.\n",
    "\n",
    "하지만 위 JSON처럼 info 안에 contact가 있고, 그 안에 email이 있는 구조는 표의 한 칸에 넣기가 매우 까다롭습니다.\n",
    "\n",
    "그래서 우리는 이 계층을 깨고 **'한 줄의 데이터'** 로 펼치는 작업이 필요합니다.\n",
    "\n",
    "보통 계층을 구분하기 위해 점(.)을 사용하곤 하죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73967b96-3a65-4fe8-926b-069d9a61a01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'USR_001',\n",
       " 'info': {'name': '김철수',\n",
       "  'contact': {'email': 'chulsoo@example.com', 'phone': '010-1234-5678'}},\n",
       " 'tags': ['developer', 'python']}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아래의 중첩된 구조(Nested Structure)의 Json 형태\n",
    "# email 컬럼의 계층 구조 info.contact.email\n",
    "{\n",
    "  \"id\": \"USR_001\",\n",
    "  \"info\": {\n",
    "    \"name\": \"김철수\",\n",
    "    \"contact\": {\n",
    "      \"email\": \"chulsoo@example.com\",\n",
    "      \"phone\": \"010-1234-5678\"\n",
    "    }\n",
    "  },\n",
    "  \"tags\": [\"developer\", \"python\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "531e032e-e557-4ac3-9d65-d96962789482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattening(평탄화): \n",
      "Index(['id', 'tags', 'info.name', 'info.contact.email', 'info.contact.phone'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "  \"id\": \"USR_001\",\n",
    "  \"info\": {\n",
    "    \"name\": \"김철수\",\n",
    "    \"contact\": {\n",
    "      \"email\": \"chulsoo@example.com\",\n",
    "      \"phone\": \"010-1234-5678\"\n",
    "    }\n",
    "  },\n",
    "  \"tags\": [\"developer\", \"python\"]\n",
    "}\n",
    "\n",
    "df = pd.json_normalize(data)\n",
    "print(f\"Flattening(평탄화): \\n{df.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a5f2b-84a2-4115-8a2c-69bec51dc0ac",
   "metadata": {},
   "source": [
    "## 2단계: 규격화 (Normalization)\n",
    "\n",
    "데이터를 DataFrame(표) 형태로 만들었습니다.\n",
    "\n",
    "이 데이터들의 형식이 올바른지 검사하고 이름을 파이썬 스타일로 바꿀 차례입니다.\n",
    "\n",
    "Pydantic 모델을 만들 때 Field의 alias 설정을 사용하면,\n",
    "\n",
    "\"데이터를 읽어올 때는 createdAt을 찾고, 파이썬 변수로는 created_at을 쓰겠다\"라고 선언할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872fc090-8a9f-4a2f-8ef7-fe3a16bbd06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic Alias\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class User(BaseModel):\n",
    "    user_id: str = Field(alias=\"id\")           # 'id'를 'user_id'로 매핑\n",
    "    user_name: str = Field(alias=\"name\")       # 'name'을 'user_name'로 매핑\n",
    "    created_at: str = Field(alias=\"createdAt\") # 'createdAt'을 'created_at'으로 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3f26545-086e-4c53-a564-6572723ca2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, PositiveInt\n",
    "\n",
    "class UserProfile(BaseModel):\n",
    "    # Field의 alias를 사용하여 camelCase를 snake_case로 매핑\n",
    "    # PositiveInt(양의 정수)를 사용하여 0보다 큰 정수임을 보장\n",
    "    user_age: PositiveInt = Field(alias=\"userAge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229d733a-5672-4df3-97e1-e959ef508f93",
   "metadata": {},
   "source": [
    "## 3단계: 효율화(Efficiency)\n",
    "\n",
    "대용량 JSON 처리 방식: 몇 천만 줄의 로그 중 특정 필드 `user_id`, `action`만 필요한 경우\n",
    "\n",
    "메모리를 아끼기 위하여 데이터를 한 줄씩 읽으면서 필요한 필드만 즉시 추출하고자 하는 경우\n",
    "\n",
    "**Streaming & Filtering 기법**\n",
    "보통 큰 파일은 한 번에 다 읽지 않고 `for line in file:` 형식을 사용합니다.\n",
    "\n",
    "이 때 각 줄(Line)에서 필요한 것만 골라내면 메모리 점유율을 획기적으로 낮출 수 있습니다.\n",
    "\n",
    "특히 필요한 데이터만 필터링 시 보안 관리에도 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4096b51a-6e2d-4d3d-9475-5398665f8a63",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1735371117.py, line 30)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m*/\u001b[39m\n     ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 대용량 로그 파일이 있다고 가정(log.jsonl - Json Lines 형식)\n",
    "# 각 줄이 하나의 Json 객체인 경우\n",
    "\n",
    "\"\"\"\n",
    "# 객체 예시\n",
    "{\n",
    "  \"user_id\": \"U12345\",\n",
    "  \"action\": \"login\",\n",
    "  \"ip_address\": \"192.168.0.1\",\n",
    "  \"user_agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)...\",\n",
    "  \"session_id\": \"sess_987654321\",\n",
    "  \"server_internal_code\": \"ERR_NONE_001\",\n",
    "  \"timestamp\": \"2026-01-06T15:00:00Z\"\n",
    "}\n",
    "\n",
    "# 객체 파싱\n",
    "with open(\"large_logs.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        # 1. 한 줄씩 읽어서 파싱(Streaming)\n",
    "        record = json.loads(line)\n",
    "\n",
    "        # 2. 필요한 필드만 추출(Filtering)\n",
    "        user_id = record.get(\"user_id\")  # 결과: \"U12345\"\n",
    "        action = record.get(\"action\")    # 결과: \"login\"\n",
    "\n",
    "        # 3. 추출한 데이터만 처리하고 나머지는 record 변수와 함께 소멸!\n",
    "        process_data(user_id, action)\n",
    "\"\"\"        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db29f0e6-c898-4183-81db-2eca81edd26b",
   "metadata": {},
   "source": [
    "## 요약 및 완성형 파이썬 스크립트\n",
    "\n",
    "| **단계**  | **기법**                  | **목적**             | **핵심 도구**               |\n",
    "| ------- | ----------------------- | ------------------ | ----------------------- |\n",
    "| **1단계** | **평탄화 (Flattening)**    | 중첩 구조를 표 형태로 변환    | `pd.json_normalize`     |\n",
    "| **2단계** | **규격화 (Normalization)** | 이름 통일 및 데이터 유효성 검증 | `Pydantic (Alias)`      |\n",
    "| **3단계** | **효율화 (Efficiency)**    | 메모리 절약 및 보안 강화     | `Streaming & Filtering` |\n",
    "\n",
    "**완성형 파이썬 스크립트**\n",
    "1. 데이터 수집: 대용량 로그 파일(`jsonl` 형식)을 한 줄씩 읽습니다.\n",
    "2. 데이터 매핑: Pydantic의 `alias`를 사용하여 `camelCase`를 `snake_case`로 바꿉ㄴ디ㅏ.\n",
    "3. 데이터 검증: 필수 필드가 있는지, 값의 타입이 맞는지 검사합니다.\n",
    "4. 필터링 및 추출: 필요한 정보만 골라내어 메모리를 아낍니다.\n",
    "\n",
    "**Pydantic V2 `model_config`**\n",
    "| **옵션명**                    | **설명**                                               | **비고**                            |\n",
    "| -------------------------- | ---------------------------------------------------- | --------------------------------- |\n",
    "| **`populate_by_name`**     | 필드 이름(snake_case)과 별칭(alias) 모두로 데이터를 읽을 수 있게 허용합니다. | API 통신 시 필수적                    |\n",
    "| **`str_strip_whitespace`** | 문자열 데이터 앞뒤의 공백을 자동으로 제거합니다.                          | 데이터 정제에 유용                       |\n",
    "| **`extra`**                | 모델에 정의되지 않은 추가 필드가 들어왔을 때의 처리를 결정합니다.                | `'ignore'`, `'allow'`, `'forbid'` |\n",
    "| **`frozen`**               | 모델을 생성한 후 값을 변경할 수 없게 만듭니다 (Immutable).              | 보안 및 안정성 강화                     |\n",
    "\n",
    "**Config Option**\n",
    "- **`ignore` (기본값):** 정의되지 않은 값은 그냥 무시하고 버립니다.\n",
    "- **`allow`:** 정의되지 않은 값도 일단 다 받아둡니다. (데이터 유실을 막고 싶을 때)\n",
    "- **`forbid`:** 정의되지 않은 값이 하나라도 들어오면 에러를 냅니다. (엄격한 규격 관리가 필요할 때)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e98a9596-f5d3-48d3-b755-04f66696d6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'U001', 'action': 'login'}, {'id': 'U002', 'action': 'logout'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pydantic import BaseModel, Field, ValidationError, ConfigDict\n",
    "\n",
    "# 1. 규격화: 데이터 모델 정의 (Pydantic)\n",
    "class UserLog(BaseModel):\n",
    "    # alias를 사용하여 API 명칭과 파이썬 변수명을 매핑합니다.\n",
    "    model_config = ConfigDict(populate_by_name=True)\n",
    "    user_id: str = Field(alias=\"userId\")\n",
    "    action_type: str = Field(alias=\"actionType\")\n",
    "\n",
    "# 2. 효율화: 스트리밍 및 필터링 함수\n",
    "def process_json_logs(json_lines):\n",
    "    processed_data = []\n",
    "    \n",
    "    for line in json_lines:\n",
    "        try:\n",
    "            # 한 줄씩 파싱 (Streaming)\n",
    "            raw_data = json.loads(line)\n",
    "            \n",
    "            # Pydantic 모델로 변환 (Validation & Normalization)\n",
    "            # 이 과정에서 camelCase인 userId가 snake_case인 user_id로 변합니다.\n",
    "            log = UserLog(**raw_data)\n",
    "            \n",
    "            # 3. 파싱 필요한 필드만 리스트에 담기 (Filtering)\n",
    "            processed_data.append({\n",
    "                \"id\": log.user_id,\n",
    "                \"action\": log.action_type\n",
    "            })\n",
    "            \n",
    "        except (ValidationError, json.JSONDecodeError) as e:\n",
    "            # 비정상 데이터는 건너뛰어 시스템 중단을 방지합니다.\n",
    "            print(f\"Skipping invalid log: {e}\")\n",
    "            \n",
    "    return processed_data\n",
    "\n",
    "# --- 실행 예시 ---\n",
    "raw_logs = [\n",
    "    '{\"userId\": \"U001\", \"actionType\": \"login\", \"ip\": \"1.1.1.1\"}',\n",
    "    '{\"userId\": \"U002\", \"actionType\": \"logout\", \"timestamp\": 1234567}'\n",
    "]\n",
    "\n",
    "results = process_json_logs(raw_logs)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c490c-56c3-4eed-b710-609ae9d511d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ad441f-78c3-4903-8cc2-0f5992035775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d580e022-da31-4f51-943c-5a7ac90c6387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
